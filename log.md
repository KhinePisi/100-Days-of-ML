This section is for my daily progress and thoughts on 100-days-of-ML challenge . 


Day 1: Monday,September 3,2018 
Today's Progress: Although I was in trouble with handling the missing data part, that's just because of my careless mistake . (I pasted the wrong csv file. Yes,call it "Beginners' mistake." =( ).However,you can see what I got from Day1 as in the following:

Summarization and advices throughout 6 steps:
Step1:  One cannot simply import those libraries(Numpy and  Pandas) without installing them . { Just a reminder for newbies like me . }
       Installation may depend upon your environment or platform but that will be escalated easily anyways. For me, I just created the local batch file in the Scripts folder of Python folder and wrote "cmd" in that "local.bat" file. After that, I run it and  started writing installation commands like "pip install numpy","pip install scipy" & "pip install pandas".Finally,importing is done by Step1     code on python shell. (My senior said that batch file is not needed and , libraries can be installed  at the same time using space,eg ."pip install numpy pandas scipy".
       
Step2:From step 2, I got the concept of (iloc) and also got to know the importance of dataset. You can see about iloc in my "Links"               section. 

Step3:For this step, I installed "sklearn" via local.bat and "scipy" .As I had some errors because of dataset, I really had to read a lot         about imputer class and my careless mistake is thankful again .( be o-p-t-i-m-i-s-t-i-c) .

Step4 and Step 5: You'd better read some documentations on these utility classes and articles about "Categorial Data","Nominal data","how                     to  transform non-numerical labels" and etc, so that you can get the idea of why lable encoding is not sufficient to                       provide to the model for training. READ DEEPLY :p

Step6: You will know the importance of data normalization from this step after surfing about this.I will share the links under my "link"          section. Kindly check it later . 


Thoughts: There's still not any tricky part in the start so that beginners can follow it well with a great motivation .For me, I'm glad that I could solve my mistake by myself and had read a lot today. 


Links: https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f
      https://datascience.stackexchange.com/questions/12321/difference-between-fit-and-fit-transform-in-scikit-learn-models
      https://en.wikipedia.org/wiki/Feature_scaling
      https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/



      
      
